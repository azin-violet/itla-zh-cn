# 前言

我很高兴您使用线性代数导论的第五版。这是我在 MIT OpenCourseWare (**ocw.mit.edu** 和 **YouTube**) 上的视频讲座的文本。我希望这些讲座对您有用 (甚至可能很有趣！)。

数百所高校选择这本书作为基本线性代数课程教材。带薪休假让我有机会准备了两个关于概率统计和数据理解的新章节。当然也还有很多其他的改进——可能只有作者自己意识到... 以下为针对学生和所有读者的新增内容:

>每小节以简短的摘要开始用以解释该节的内容。当您阅读新章节或者阅读之前的章节以在脑中回顾和组织已学内容，这些行可以作为快速指南并能帮助记忆。

另一个巨大的改变是本书的网站 **math.mit.edu/linearalgebra**。网站现在包含了本书中 Problem Sets 部分的答案。由于空间无限，这比只打印简短的答案更加灵活。目前有三个主要网站：

**ocw.mit.edu** 该 OpenCourseWare 网站有来自数千名学生和线性代数教师的信息。18.06 和 18.06SC 等课程包含完整学期课程的视频讲座。讲座根据本教材提供了对整个科目独立的复习——使得教授的时间保持空闲，而学生的则可能学到凌晨2点。(读者完全可以不用待在教室里。) 世界上有六百万人观看了这些视频 (amazing)。希望它们对您有帮助。

**web.mit.edu/18.06** 该网站包含当前学期已讲课程的家庭作业和测试 (含解答)，最早可以追溯到1996年。还有一些复习题，Java演示程序，课程代码和阅读材料 (包括视频讲座)。我的目标是通过能提供的所有课程材料尽可能让这本书对您有用。 

**math.mit.edu/linearalgebra** 这已成为一个活跃的网站。现在包含 Solutions to Exercises 模块——提供阐述想法的场所。同时还有许多不同来源的新练习——有练习题，教科书的例题，MATLAB，*Julia* 和 *Python* 代码以及一系列的考试题 (包括 18.06 和其他课程) 用于复习。

欢迎访问线性代数网站。建议请发送至邮箱 <linearalgebrabook@gmail.com>。

## 第五版

封面展示了**四个基本的子空间**——左边的行空间和零空间，右边的列空间和 \\(A^\mathrm{T}\\) 的零空间。像这样说明一门学科的中心思想是不同寻常的！当您在第 3 章遇到这四个空间时，您将会理解为什么这张图片对线性代数如此重要。

在我的第一本书中，它们被命名为四个基本子空间并从一个矩阵 \\(A\\) 出发。\\(A\\) 的每一行是 \\(n\\) 维空间的一个向量。当矩阵有 \\(m\\) 行时，每一列是 \\(m\\) 维空间的一个向量。在线性代数中的关键操作是做***列向量的线性组合***。这正是矩阵——向量乘法的结果。*\\(Ax\\) 是 \\(A\\) 的列的一个线性组合*。

当我们取遍列向量的所有线性组合 \\(Ax\\)，就得到了*列空间*。如果这个空间包含向量 \\(b\\)，我们就可以解方程 \\(Ax=b\\)。

请特别注意1.3节，其中这些想法很早就出现了——并附有两个具体示例。您不必强迫自己在一天了解向量空间的所有细节！但在1.3节您将会看到本书中的第一个矩阵，以及它的列空间的一个图像。甚至包含 *逆* 矩阵以及它与微积分的联系。您将会以一种最好和最有效的方式学习线性代数语言：应用它。

每一章的每小节的结尾都有大量的习题。它们要求您运用在该小节的思想——列空间的维数，空间的一组基，矩阵 \\(A\\) 的秩，逆，行列式和特征值。许多问题要求在一个小矩阵上动手进行计算, 它们广受好评。*Challenge Problems* 部分的习题更进一步，可能也更深入。下面给出四个例子：

*Section* 2.1: Which row exchanges of a Sudoku matrix produce another Sudoku matrix ?

*Section* 2.7: If \\(P\\) is a permutation matrix, why is some power \\(P^k\\) equal to \\(I\\) ?

*Section* 3.4: if \\(Ax=b\\) and \\(Cx=b\\) have the same solutions for every \\(b\\), does \\(A\\) equal \\(C\\) ?

*Section* 4.1: What conditions on the four vectors \\(r,\ n,\ c,\ l\\) allow them to be bases for the row space, the nullspace, the column space, and the left nullspace of a 2 by 2 matrix ?

## 写在课程前面

方程 \\(Ax=b\\) 可以线性组合的语言加以解释。向量 \\(Ax\\) 可以认为是 *\\(A\\) 的列的一个线性组合*。这个方程实际上是在求一个能够生成向量 \\(b\\) *线性组合*。解向量 \\(x\\) 可以从三个层次进行求解，这三个层次都很重要：
1. ***直接解法*** 通过前向消除和后向替换来求解 \\(x\\)。
2. ***矩阵解法*** 使用逆矩阵求解：\\(x=A^{-1}b\\) (如果 \\(A\\) 有逆)。
3. ***特解*** (对于 \\(Ay=b\\)) plus ***零解*** (对于 \\(Az=0\\))。本书封面展示了解向量空间 \\(x=y+z\\)。

直接消除法是科学计算中使用最为频繁的算法。将矩阵 \\(A\\) 变成三角形——之后能够快速得到解。我们也能对四个子空间有一个基本的了解。但不会一直把时间花在练习消除法... 之后会有一些好的想法。

每一台新的超级计算机的速度都会在 \\(Ax=b\\) 上测试：单纯的线性代数。但即使是超级计算机也不想计算逆矩阵：太慢了。矩阵逆给了一个最简洁的求解公式 \\(x=A^{-1}b\\) 但却不是计算速度最快的。同时每个人都必须知道行列式的计算会更慢——线性代数课程不应该从 \\(n \times n\\) 行列式公式开始。这些公式有一席之地，但不是第一位。

## 本书结构

在这篇序言中，您可以了解到本书的风格及其目标。这个目标是严肃的，要向您解释线性代数这个美丽又有用的数学分支。您将会看到线性代数的应用是如何强化其核心思想的。这本书循序渐进地从数字讲到向量，再到子空间。每一过程都是自然而然的，每个人都能理解。

以下是关于使用本书学习和教学的12点建议：
1. 第 1 章首先讲述向量和点积。如果之前的课堂已经了解过，可以重点关注线性组合。1.3节提供了三个独立的向量——线性组合能够填满整个3维空间，和位于一个平面的三个相关向量。***这两个例子是学习线性代数的开始***。

2. 第 2 章 \\(Ax=b\\) 的行的图像和列的图像。线性代数的核心就在于 \\(A\\) 的行和 \\(A\\) 的列之间的联系：相同的数目但非常不同的图像。然后开始矩阵代数：一个消除矩阵 (elimination matrix) \\(E\\) 乘以 \\(A\\) 得到零。目标是掌握整个过程——从 \\(A\\) 开始，与一系列的 \\(E\\) 相乘，最后得到 \\(U\\)。  
消除 (Elimination) 从美丽的形式 \\(A=LU\\) 中可见一斑。***下三角*** \\(L\\) 包含了前向消去的步骤，\\(U\\) 是 ***上三角*** 的，用于后向替换过程。

3. 第 3 章讲述线性代数的最佳层面：***子空间***。列空间包含列的所有线性组合。一个关键问题是：***这些列中有多少是必要的*** ？答案会告诉我们列空间的维数以及 \\(A\\) 的关键信息。我们最后会得出线性代数的基本定理。

4. 当方程个数多于未知数个数时，几乎可以确定 \\(Ax=b\\) 没有解。我们不能抛弃每一接近当不完全精确的度量！当使用 ***最小二乘*** 求解时，关键点将会是矩阵 \\(A^\mathrm{T}A\\)。当 \\(A\\) 是矩形时，这个奇妙的矩阵在应用数学中无处不在。

5. 行列式给出了之前的所有公式——Cramer法则，逆矩阵，\\(n\\) 维体积。我们不用这些公式进行计算。这些公式计算的很慢。但是 \\(\det A=0\\) 表示矩阵是奇异的：这是特征值的关键。

6. ***6.1节 解释 \\(2 \times 2\\) 矩阵的特征值***。许多课程想提前讲述特征值。直接从第 3 章来到本章是完全合理的，因为 \\(2 \times 2\\) 矩阵的行列式是简单的。*关键等式* 是 \\(Ax=\lambda x\\)。   
特征值和特征向量是理解方阵的相当新奇的方法。它们不仅用于 \\(Ax=b\\)，还用于动力学方程比如 \\(du/dt=Au\\)。这里的思想总是一致的：从特征向量的方向着手。在这些特殊的方向上，\\(A\\) 像一个单独的数 (特征值 \\(\lambda\\))一样作用并且此时问题是一维的。

    第 6 章一个本质上的重点是 ***对角化对称矩阵***。当所有的特征值大于零时，矩阵被称为“正定的”。这个重要概念联系了课程的全部知识点——正主元 (pivot)、行列式和特征值以及能量。我努力在书中达到这一点，并用例子加以解释。

7. 第 7 章是全新的一章。该章介绍了 ***奇异值*** 和 ***奇异向量***。它们将所有矩阵分成简单的部分，按重要性排序。您将会看到一种压缩图片的方法。特别是您可以分析一个充满数据的矩阵。

8. 第 8 章阐述 ***线性变换***。这是没有坐标轴的几何，没有坐标的代数。当选择一组基时，我们得到了尽可能好的矩阵。

9. 第 9 章从实数和实向量转向复向量和复矩阵。傅里叶矩阵 (Fourier matrix) \\(F\\) 将是我们见过的最重要的复矩阵。并且快速傅里叶变换 (快速乘以 \\(F\\) 和 \\(F^{-1}\\)) 是革命性的。

10. 第 10 章通篇包含应用，远多于任何一门单独课程所需：  
    10.1 *图和网络*——基尔霍夫定律的边缘节点矩阵  
    10.2 *工程中的矩阵*——与矩阵方程平行的微分方程   
    10.3 *马尔科夫矩阵*——出现在谷歌的 *PageRank* 算法中   
    10.4 *线性编程*——新的约束 \\(x \geq 0\\) 和最小化代价  
    10.5 *傅里叶级数*——用于函数和数字信号处理  
    10.6 *计算机图形学*——通过矩阵移动、旋转和压缩图像  
    10.7 *密码学中的线性代数*——这一新部分编写起来很有趣。希尔密码不太安全。它使用模运算：从 \\(0\\) 到 \\(p-1\\) 的整数。乘法得到 \\(4 \times 5 \equiv 1(mod\ 19)\\)。对此解码得到 \\(4^{-1} \equiv 5\\)。


11. 线性代数课程应该怎样包含计算？这可以得到对矩阵的新理解——每节课都会找到一个平衡点。MATLAB 和 *Maple* 以及 *Mathematica* 在不同方面非常强大。*Julia* 和 *Python* 都是开源的且可以直接在 Web 上直接获取。那些较新的编程语言同样也十分强大！

    基本命令从第 2 章开始。然后第 11 章转向专业算法。您可以在网站上上传和下载本课程的代码。

12. 关于概率和统计的第 12 章是新增的，具有真正重要的应用。当随机变量不相互独立时我们得到协方差矩阵。幸运的是它们是对称正定的。此时需要第 6 章的线性代数知识。

## 线性代数的多样性

微积分主要是关于一种特殊运算 (微分) 和其逆运算 (积分)。当然我认为微积分是很重要的... 但数学的许多应用是离散的不是连续的，是数字的而不是模拟的。数据的时代已经来临！你将会在我的网站上找到一篇名为 “Too Much Calculus” 的轻松文章。***事实上，向量和矩阵已经成为人们需要了解的语言***。

该语言的一部分是奇妙多样的举证。让我举三个例子 (依次是对称矩阵、正交矩阵和三角矩阵)：
\\[
\begin{bmatrix}2&-1&0&0\\\\-1&2&-1&0\\\\0&-1&2&-1\\\\0&0&-1&2\end{bmatrix}\ 
\frac{1}{2}\begin{bmatrix}1&1&1&1\\\\1&-1&1&-1\\\\1&1&-1&-1\\\\1&-1&-1&1\end{bmatrix}\ 
\begin{bmatrix}1&1&1&1\\\\0&1&1&1\\\\0&0&1&1\\\\0&0&0&1\end{bmatrix}
\\]

关键目标是学会 “阅读” 矩阵。你需要了解这些数字的意义。这其实是数学的本质——模式及其所代表的含义。

我使用 *斜体* 和 **粗体** 标出每页的关键词。我知道你有时候想快速阅读，寻找重要的行。

最后想分享一些想法给老师。你可能认为方向是对的，并且想知道你的学生是否准备好。***给他们一个机会***！数以千记的学生经常写信给我，经常提些建议，同时令人惊讶的是更多是表达感谢。他们知道这本书有一个目标，因为老师和教材都站在他们这边。线性代数是一门很棒的学科，好好享受它吧。

## 致谢

人生中最令人鼓舞的事是感觉自己正在做一些对自己人生有价值的事。数以百计的慷慨的读者向本书贡献了他们的想法、例子和更正 (还有最爱的矩阵)。*谢谢你们所有人*。

Ashley C. Fernandes 对本书的作成功不可没。他负责准备相应的 \\(\LaTeX\\) 文件。在他的支持下本书更改了6次，既是为了准确性同时也是自身的严格要求。和朋友一起共事是十分令人愉快的一件事。

MIT 数学系内外的朋友都很棒。Alan Edelman 负责 *Julia* 以及更多的部分，Alex Townsend 负责 7.1 节的标志示例，而 Peter Kempthorne 负责 7.3 节的金融示例：这些都很突出。Don Spickler 的密码学网站简直太棒了。我感谢 Jon Bloom、Jack Dongarra、Hilary Finucane、Pavel Grinfeld、Randy LeVeque、David Vogan、Liang Wang 和 Karen Willcox。7.3节的 “eigenfaces” 由 Matthew Turk 和 Jeff Jauregui 负责。Raj Rao 在密歇根大学的精彩课程加速了向奇异值迈出的一大步。

这本书的诞生主要归功于我在牛津大学的愉快假期。谢谢 Nick Trefethen 和其他所有人。其实是本书的读者！祝您工作顺利。

## 作者背景

这是我关于线性代数的第 9 本教材，我犹豫着要不要写我自己。重要的数学以及读者。接下来的段落添加了一些简短和个人的内容，以此表明本书是由人编写的。

我出生在芝加哥，在华盛顿、辛辛那提和圣路易斯上过学。我的大学是麻省理工学院 (我的线性代数课程 *非常抽象*)。之后去了牛津大学和加州大学洛杉矶分校，然后回到麻省理工学院很长一段时间。我不知道有多少学生学过 18.06 课程 (包括 ***ocw.mit.edu*** 上的视频的话超过了6百万)。采用新方式授课的时机是正确的，因为这个奇妙的主题只向数学专业的学生展示——我们需要向世界开放线性代数课程。

我对教授数学的生活非常感激，这种感激难以用言语表达。

Gilbert Strang

### 附言   

我希望我下一本书 (2018?) 包含 *数据学习* 相关内容。这门学科正在迅速成长，尤其是“深度学习”。通过知晓基于由旧数据组成的训练集的函数，我们可以估计基于新数据的函数。这个估计仅仅使用一个简单的线性函数 \\(f(x)=\max (0,x)\\)。我们对 \\(n\\) 个矩阵乘法进行优化来实现深度的学习：\\(\boldsymbol{x}_1=f(A_1 \boldsymbol{x}+\boldsymbol{b}_1),\boldsymbol{x}_2=f(A_2 \boldsymbol{x}_1+\boldsymbol{b}_2), \ldots, \boldsymbol{x}_n=f(A_n \boldsymbol{x}\_{n-1}+\boldsymbol{b}_n)\\)。在输入 \\(\boldsymbol{x}\\) 和输出 \\(\boldsymbol{x}_n\\) 之间是 \\(n-1\\) 个隐藏层——它们基于训练集估计 \\(F(\boldsymbol{x})\\)。

